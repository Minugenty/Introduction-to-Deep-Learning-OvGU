{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VZ9poLQMtDV"
      },
      "source": [
        "# Assignment 3 - Keras and CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NJhVw0kP938"
      },
      "source": [
        "# CNN on MNIST with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1MQKgboLMjvy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "jK2df7EiP3dg",
        "outputId": "71c3ab62-4daa-456a-82e6-e11b6f01af30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bd5be2ce860>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hk7FauB2Qrwq"
      },
      "outputs": [],
      "source": [
        "# data is not reshaped to 784 anymore, but 28x28x1\n",
        "# the 1 color channel!! this is important\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxJlxybSiXl",
        "outputId": "ead6e92a-801e-4a09-fa78-9b66b9e6adda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 896906 (3.42 MB)\n",
            "Trainable params: 896906 (3.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YWkZJsvWO3X",
        "outputId": "c5afcee8-d226-483c-d9c1-447a3f461f06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7bd5b8a8c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7bd5b8a8c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.30788254737854 Accuracy: 0.0859375\n",
            "Loss: 0.12049482017755508 Accuracy: 0.8804687261581421\n",
            "Loss: 0.08594903349876404 Accuracy: 0.9673437476158142\n",
            "Loss: 0.03273867815732956 Accuracy: 0.9779687523841858\n",
            "Loss: 0.08172497153282166 Accuracy: 0.979296863079071\n",
            "Loss: 0.039994750171899796 Accuracy: 0.9844141602516174\n",
            "Loss: 0.034519489854574203 Accuracy: 0.9882031083106995\n",
            "Loss: 0.09444170445203781 Accuracy: 0.9867968559265137\n",
            "Loss: 0.03244532272219658 Accuracy: 0.9879687428474426\n",
            "Loss: 0.010296731255948544 Accuracy: 0.9879687428474426\n",
            "Loss: 0.018515627831220627 Accuracy: 0.9906798005104065\n",
            "Loss: 0.020319871604442596 Accuracy: 0.9912499785423279\n",
            "Loss: 0.017893966287374496 Accuracy: 0.9903905987739563\n",
            "Loss: 0.03626560419797897 Accuracy: 0.9903125166893005\n",
            "Loss: 0.021994851529598236 Accuracy: 0.9925781488418579\n",
            "Loss: 0.01656433939933777 Accuracy: 0.9956140518188477\n",
            "Loss: 0.007998624816536903 Accuracy: 0.9939062595367432\n",
            "Loss: 0.014338366687297821 Accuracy: 0.9934375286102295\n",
            "Loss: 0.014589782804250717 Accuracy: 0.9944531321525574\n",
            "Loss: 0.0025576509069651365 Accuracy: 0.9935777187347412\n",
            "Loss: 0.006306955590844154 Accuracy: 0.9967187643051147\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC-Dn3bFYtF7",
        "outputId": "fbcdd1e1-70c3-49e5-faa9-30878a5f88d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.9922000169754028\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufZkZyRid_4f"
      },
      "source": [
        "# CNN on Fashion-MNIST with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "cjbtUuDSeEYd",
        "outputId": "c73a8b64-4a02-4854-d808-6c71e4cdf164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bd5b6ff7f10>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load data\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P015gLDLh-BE",
        "outputId": "8fdea20e-09da-4d62-fe5b-2f0c0edc086b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mtE8M64tiAox"
      },
      "outputs": [],
      "source": [
        "# data is not reshaped to 784 anymore, but 28x28x1\n",
        "# the 1 color channel!! this is important\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUdqNhkiiRI9",
        "outputId": "bc21aa98-2fbf-4bf2-f067-478d359062fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 896906 (3.42 MB)\n",
            "Trainable params: 896906 (3.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYzfffp3iVsN",
        "outputId": "fc0d3522-8c57-4142-ba34-51547bebe66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.299467086791992 Accuracy: 0.140625\n",
            "Loss: 0.49667584896087646 Accuracy: 0.757031261920929\n",
            "Loss: 0.4230605363845825 Accuracy: 0.8573437333106995\n",
            "Loss: 0.2995346784591675 Accuracy: 0.8726562261581421\n",
            "Loss: 0.3138021230697632 Accuracy: 0.8875781297683716\n",
            "Loss: 0.29194939136505127 Accuracy: 0.8968514800071716\n",
            "Loss: 0.2453336864709854 Accuracy: 0.9055469036102295\n",
            "Loss: 0.27008959650993347 Accuracy: 0.907421886920929\n",
            "Loss: 0.2730228304862976 Accuracy: 0.9129687547683716\n",
            "Loss: 0.22978344559669495 Accuracy: 0.9139843583106995\n",
            "Loss: 0.1812775582075119 Accuracy: 0.9244987368583679\n",
            "Loss: 0.19839775562286377 Accuracy: 0.9216406345367432\n",
            "Loss: 0.16981813311576843 Accuracy: 0.9253125190734863\n",
            "Loss: 0.23413342237472534 Accuracy: 0.9311718940734863\n",
            "Loss: 0.19653330743312836 Accuracy: 0.9271875023841858\n",
            "Loss: 0.22894348204135895 Accuracy: 0.9384398460388184\n",
            "Loss: 0.15766581892967224 Accuracy: 0.9371093511581421\n",
            "Loss: 0.10780102759599686 Accuracy: 0.9389843940734863\n",
            "Loss: 0.26365038752555847 Accuracy: 0.9375\n",
            "Loss: 0.05283737927675247 Accuracy: 0.9448621273040771\n",
            "Loss: 0.19289140403270721 Accuracy: 0.9482812285423279\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPYEBYtRiWvs",
        "outputId": "3928ab3b-a8a6-42a8-fed5-14c27a49c30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.9214000105857849\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jOvzUPQiarX"
      },
      "source": [
        "# CNN on CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Qrf24S3Fifww",
        "outputId": "3a93e79c-7049-4e6e-e75d-949d5fa878c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n",
            "[6]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bd5b05e9f90>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cifar = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ent3Tw8dis7h",
        "outputId": "80ae26ee-f21b-4b36-99c6-098e4caa6916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HjK5gHsKi0_X"
      },
      "outputs": [],
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5sgPL_jM2oT"
      },
      "source": [
        "## Basic Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFdXR2xRjmUw",
        "outputId": "22e16489-3190-41d8-b669-68324c38ca9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1143242 (4.36 MB)\n",
            "Trainable params: 1143242 (4.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgMwa-r5kGHd",
        "outputId": "a93bdb2c-ba2c-4b2c-c5a2-4dd4b6e042f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.313772201538086 Accuracy: 0.0625\n",
            "Loss: 1.6119433641433716 Accuracy: 0.36265623569488525\n",
            "Loss: 1.2534593343734741 Accuracy: 0.49937498569488525\n",
            "Loss: 1.0956857204437256 Accuracy: 0.560546875\n",
            "Loss: 0.9528722763061523 Accuracy: 0.6176286339759827\n",
            "Loss: 0.8539584279060364 Accuracy: 0.6560156345367432\n",
            "Loss: 0.9738563299179077 Accuracy: 0.6673437356948853\n",
            "Loss: 0.8881906867027283 Accuracy: 0.6867969036102295\n",
            "Loss: 0.937796413898468 Accuracy: 0.7085162997245789\n",
            "Loss: 0.7728348970413208 Accuracy: 0.7258594036102295\n",
            "Loss: 0.5797577500343323 Accuracy: 0.7264062762260437\n",
            "Loss: 0.9365914463996887 Accuracy: 0.733203113079071\n",
            "Loss: 0.7955054044723511 Accuracy: 0.7372961044311523\n",
            "Loss: 0.6278781294822693 Accuracy: 0.7642187476158142\n",
            "Loss: 0.799414873123169 Accuracy: 0.7649999856948853\n",
            "Loss: 0.6722870469093323 Accuracy: 0.7702343463897705\n",
            "Loss: 0.4305873215198517 Accuracy: 0.7819165587425232\n",
            "Loss: 0.39597874879837036 Accuracy: 0.7997656464576721\n",
            "Loss: 0.5812735557556152 Accuracy: 0.7994531393051147\n",
            "Loss: 0.6177864074707031 Accuracy: 0.7995312213897705\n",
            "Loss: 0.5232319235801697 Accuracy: 0.816185712814331\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUHrpMtoJqMy",
        "outputId": "4554a7a4-214e-4442-d831-5340042e6cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.751800000667572\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKiyaq3PLxR_"
      },
      "source": [
        "## Increased Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et3UY2aaKB93",
        "outputId": "57da51fc-8bda-4339-f71b-cecb5742f58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Loss: 0.3578989803791046 Accuracy: 0.8984375\n",
            "Loss: 0.4886166751384735 Accuracy: 0.8423437476158142\n",
            "Loss: 0.4636472761631012 Accuracy: 0.8324999809265137\n",
            "Loss: 0.47139206528663635 Accuracy: 0.8296874761581421\n",
            "Loss: 0.42572832107543945 Accuracy: 0.8281053900718689\n",
            "Loss: 0.4382883608341217 Accuracy: 0.8716406226158142\n",
            "Loss: 0.5605603456497192 Accuracy: 0.8676562309265137\n",
            "Loss: 0.4501621723175049 Accuracy: 0.8589843511581421\n",
            "Loss: 0.23769456148147583 Accuracy: 0.8711574673652649\n",
            "Loss: 0.33114784955978394 Accuracy: 0.9032031297683716\n",
            "Loss: 0.3298453986644745 Accuracy: 0.8897656202316284\n",
            "Loss: 0.3463050425052643 Accuracy: 0.8881250023841858\n",
            "Loss: 0.16716229915618896 Accuracy: 0.8980551958084106\n",
            "Loss: 0.27601245045661926 Accuracy: 0.9264062643051147\n",
            "Loss: 0.21654155850410461 Accuracy: 0.9120312333106995\n",
            "Loss: 0.20400181412696838 Accuracy: 0.9096875190734863\n",
            "Loss: 0.24001379311084747 Accuracy: 0.9252666234970093\n",
            "Loss: 0.08595672994852066 Accuracy: 0.949999988079071\n",
            "Loss: 0.20876997709274292 Accuracy: 0.935546875\n",
            "Loss: 0.2749711871147156 Accuracy: 0.9266406297683716\n",
            "Loss: 0.14666394889354706 Accuracy: 0.9393820762634277\n",
            "Epoch 1\n",
            "Loss: 0.08938530087471008 Accuracy: 0.9609375\n",
            "Loss: 0.049854081124067307 Accuracy: 0.9693750143051147\n",
            "Loss: 0.08092812448740005 Accuracy: 0.9541406035423279\n",
            "Loss: 0.24859502911567688 Accuracy: 0.9393749833106995\n",
            "Loss: 0.09611760079860687 Accuracy: 0.9432246088981628\n",
            "Loss: 0.10518775880336761 Accuracy: 0.9720312356948853\n",
            "Loss: 0.1311550736427307 Accuracy: 0.9666406512260437\n",
            "Loss: 0.09871481359004974 Accuracy: 0.9642187356948853\n",
            "Loss: 0.1752479076385498 Accuracy: 0.9535759091377258\n",
            "Loss: 0.05026533082127571 Accuracy: 0.9781249761581421\n",
            "Loss: 0.15485945343971252 Accuracy: 0.97265625\n",
            "Loss: 0.1456139087677002 Accuracy: 0.9644531011581421\n",
            "Loss: 0.021808985620737076 Accuracy: 0.9642409086227417\n",
            "Loss: 0.06128480285406113 Accuracy: 0.9832812547683716\n",
            "Loss: 0.04016837477684021 Accuracy: 0.9744531512260437\n",
            "Loss: 0.06689977645874023 Accuracy: 0.9743750095367432\n",
            "Loss: 0.0537884421646595 Accuracy: 0.9644761681556702\n",
            "Loss: 0.054241787642240524 Accuracy: 0.9819531440734863\n",
            "Loss: 0.05430592596530914 Accuracy: 0.9743750095367432\n",
            "Loss: 0.15963861346244812 Accuracy: 0.9760937690734863\n",
            "Loss: 0.08291029930114746 Accuracy: 0.9764742851257324\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "for i in range(epochs):\n",
        "  print(\"Epoch {}\".format(i))\n",
        "  for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "      if step > train_steps:\n",
        "          break\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          logits = model(image_batch)\n",
        "          # loss format is generally: first argument targets, second argument outputs\n",
        "          loss = loss_fn(label_batch, logits)\n",
        "\n",
        "      # if you didn't build the model, it is important that you get the variables\n",
        "      # AFTER the model has been called the first time\n",
        "      variables = model.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "\n",
        "      optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "      train_acc_metric(label_batch, logits)\n",
        "\n",
        "      if not step % 100:\n",
        "          # this is different from before. there, we only evaluated accuracy\n",
        "          # for one batch. Now, we always average over 100 batches\n",
        "          print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "          train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lR4Q_pDNDBP"
      },
      "source": [
        "## Adjusting Filter size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-sHXp3sMYQe",
        "outputId": "b868660f-b5a8-462d-bc5c-a435f8c83d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1273226 (4.86 MB)\n",
            "Trainable params: 1273226 (4.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TNkt5yYUxOb",
        "outputId": "3631b6e0-2803-4ff4-aca5-2506594ce2b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.300408363342285 Accuracy: 0.140625\n",
            "Loss: 1.4709084033966064 Accuracy: 0.34281250834465027\n",
            "Loss: 1.3278982639312744 Accuracy: 0.4861718714237213\n",
            "Loss: 1.0937402248382568 Accuracy: 0.5553125143051147\n",
            "Loss: 1.0856468677520752 Accuracy: 0.6079830527305603\n",
            "Loss: 1.1819185018539429 Accuracy: 0.6517968773841858\n",
            "Loss: 0.9781569242477417 Accuracy: 0.6773437261581421\n",
            "Loss: 0.9115937948226929 Accuracy: 0.6922656297683716\n",
            "Loss: 0.8123372197151184 Accuracy: 0.7002038955688477\n",
            "Loss: 0.7441233396530151 Accuracy: 0.729687511920929\n",
            "Loss: 0.7711324691772461 Accuracy: 0.7342968583106995\n",
            "Loss: 0.8546478748321533 Accuracy: 0.7414844036102295\n",
            "Loss: 0.546359121799469 Accuracy: 0.7521957159042358\n",
            "Loss: 0.6250467896461487 Accuracy: 0.770703136920929\n",
            "Loss: 0.599277138710022 Accuracy: 0.7728124856948853\n",
            "Loss: 0.6361522674560547 Accuracy: 0.7852343916893005\n",
            "Loss: 0.4698387682437897 Accuracy: 0.7851317524909973\n",
            "Loss: 0.46752747893333435 Accuracy: 0.8149999976158142\n",
            "Loss: 0.5409901738166809 Accuracy: 0.8071874976158142\n",
            "Loss: 0.5575997233390808 Accuracy: 0.8109375238418579\n",
            "Loss: 0.50568026304245 Accuracy: 0.8277133107185364\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Zu6aMiU3P5",
        "outputId": "e954622d-f64f-43cc-864d-4f8d9d381e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.748199999332428\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9OLiMLFWwO0"
      },
      "source": [
        "## Changed Kernel size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYAL1t3IWs54",
        "outputId": "89721bd6-d768-440b-b827-d320ad0e2de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 64)        4864      \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 128)       204928    \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       409728    \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1669514 (6.37 MB)\n",
            "Trainable params: 1669514 (6.37 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "# Kernel size increased to 5 x 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(5, 5), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(5, 5), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(5, 5), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHNAuuEhW7C2",
        "outputId": "df4b4576-dddf-4b77-ee57-251965bea4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.308818817138672 Accuracy: 0.0859375\n",
            "Loss: 1.8100690841674805 Accuracy: 0.29554688930511475\n",
            "Loss: 1.3825974464416504 Accuracy: 0.4495312571525574\n",
            "Loss: 1.3755528926849365 Accuracy: 0.516796886920929\n",
            "Loss: 1.027834177017212 Accuracy: 0.5659504532814026\n",
            "Loss: 1.2016741037368774 Accuracy: 0.6012499928474426\n",
            "Loss: 1.011459231376648 Accuracy: 0.6318749785423279\n",
            "Loss: 0.9258040189743042 Accuracy: 0.6460156440734863\n",
            "Loss: 0.8408719301223755 Accuracy: 0.6685225963592529\n",
            "Loss: 0.8174552321434021 Accuracy: 0.7033593654632568\n",
            "Loss: 0.8387763500213623 Accuracy: 0.7028124928474426\n",
            "Loss: 0.6923415064811707 Accuracy: 0.7178124785423279\n",
            "Loss: 0.5332013368606567 Accuracy: 0.731179416179657\n",
            "Loss: 0.547999918460846 Accuracy: 0.762499988079071\n",
            "Loss: 0.9510667324066162 Accuracy: 0.758984386920929\n",
            "Loss: 0.6264247894287109 Accuracy: 0.7576562762260437\n",
            "Loss: 0.4403444230556488 Accuracy: 0.7814460396766663\n",
            "Loss: 0.5265405178070068 Accuracy: 0.8071093559265137\n",
            "Loss: 0.6505845785140991 Accuracy: 0.8076562285423279\n",
            "Loss: 0.44376108050346375 Accuracy: 0.798828125\n",
            "Loss: 0.3269154727458954 Accuracy: 0.831163763999939\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ciX3-F_W96a",
        "outputId": "83c2b2d0-fe2d-40df-e490-179bd5ad8093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7354999780654907\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpCU_vQCXCU-",
        "outputId": "fe5ef126-02d4-4f28-e6ec-b2cf2a13e0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 64)        43264     \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 128)       1843328   \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       3686528   \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6623114 (25.27 MB)\n",
            "Trainable params: 6623114 (25.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "# Kernel size increased to 15 x 15\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(15, 15), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(15, 15), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(15, 15), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3A6SLiBXvQZ",
        "outputId": "c891b6b4-474b-4a45-d5de-b43a83f4e1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.3044495582580566 Accuracy: 0.09375\n",
            "Loss: 2.0173513889312744 Accuracy: 0.18640625476837158\n",
            "Loss: 1.902409553527832 Accuracy: 0.3147656321525574\n",
            "Loss: 1.6341030597686768 Accuracy: 0.3692968785762787\n",
            "Loss: 1.518965721130371 Accuracy: 0.4024466872215271\n",
            "Loss: 1.6444857120513916 Accuracy: 0.42625001072883606\n",
            "Loss: 1.542420506477356 Accuracy: 0.44148436188697815\n",
            "Loss: 1.5198781490325928 Accuracy: 0.4642968773841858\n",
            "Loss: 1.1789462566375732 Accuracy: 0.4933343827724457\n",
            "Loss: 1.3044432401657104 Accuracy: 0.515625\n",
            "Loss: 1.250166654586792 Accuracy: 0.5307812690734863\n",
            "Loss: 1.3082211017608643 Accuracy: 0.520703136920929\n",
            "Loss: 1.172440528869629 Accuracy: 0.5572459101676941\n",
            "Loss: 1.2003642320632935 Accuracy: 0.5871875286102295\n",
            "Loss: 1.009019374847412 Accuracy: 0.5892968773841858\n",
            "Loss: 1.202378273010254 Accuracy: 0.5887500047683716\n",
            "Loss: 1.1026885509490967 Accuracy: 0.6188833117485046\n",
            "Loss: 0.796983540058136 Accuracy: 0.6596875190734863\n",
            "Loss: 0.9579808115959167 Accuracy: 0.6458593606948853\n",
            "Loss: 1.0653945207595825 Accuracy: 0.6332812309265137\n",
            "Loss: 0.6656548380851746 Accuracy: 0.6800501942634583\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTFrE8SkXy0k",
        "outputId": "a6243e79-b081-4e1f-b66a-f5005b0b81f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.576200008392334\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMSBtUnsX1GL",
        "outputId": "b892cd9d-e1fd-4177-98ae-f28d5ec8a018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 64)        196672    \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 128)       8388736   \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       16777344  \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26412746 (100.76 MB)\n",
            "Trainable params: 26412746 (100.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "# Kernel size increased to 32 x 32\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(32, 32), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(32, 32), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(32, 32), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioc6xaXhYBMi",
        "outputId": "6d6e5a92-1134-4e81-8057-80aac8230f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.3053855895996094 Accuracy: 0.0703125\n",
            "Loss: 2.3026351928710938 Accuracy: 0.10257812589406967\n",
            "Loss: 2.3032195568084717 Accuracy: 0.09437499940395355\n",
            "Loss: 2.302743911743164 Accuracy: 0.09656249731779099\n",
            "Loss: 2.3021841049194336 Accuracy: 0.0989648699760437\n",
            "Loss: 2.3013267517089844 Accuracy: 0.10015624761581421\n",
            "Loss: 2.301849365234375 Accuracy: 0.09523437172174454\n",
            "Loss: 2.302509069442749 Accuracy: 0.09656249731779099\n",
            "Loss: 2.302917718887329 Accuracy: 0.09841593354940414\n",
            "Loss: 2.3031044006347656 Accuracy: 0.10398437827825546\n",
            "Loss: 2.3029985427856445 Accuracy: 0.09882812201976776\n",
            "Loss: 2.302980899810791 Accuracy: 0.09648437798023224\n",
            "Loss: 2.3025848865509033 Accuracy: 0.09778857976198196\n",
            "Loss: 2.301708936691284 Accuracy: 0.10437499731779099\n",
            "Loss: 2.3027496337890625 Accuracy: 0.09531249850988388\n",
            "Loss: 2.303593158721924 Accuracy: 0.09734375029802322\n",
            "Loss: 2.30147647857666 Accuracy: 0.10100376605987549\n",
            "Loss: 2.303168296813965 Accuracy: 0.09476562589406967\n",
            "Loss: 2.3026509284973145 Accuracy: 0.10109374672174454\n",
            "Loss: 2.3024799823760986 Accuracy: 0.09734375029802322\n",
            "Loss: 2.30301833152771 Accuracy: 0.09747490286827087\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlzOBNsTYE7-",
        "outputId": "ec4a57cc-1832-4385-a66b-45c8bb511a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.10000000149011612\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSeDENp6Ycua",
        "outputId": "fb97ec93-95c6-4b99-f70c-874da42112c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 64)        256       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 128)       8320      \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       16512     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1075082 (4.10 MB)\n",
            "Trainable params: 1075082 (4.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "# Kernel size decreased to 1 x 1\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(1, 1), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(1, 1), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(1, 1), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtcT8pa0YrLv",
        "outputId": "b6587dab-4310-45b5-f029-5fef7f2ed734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2988948822021484 Accuracy: 0.1484375\n",
            "Loss: 1.54450523853302 Accuracy: 0.3043749928474426\n",
            "Loss: 1.531832218170166 Accuracy: 0.4344531297683716\n",
            "Loss: 1.3503397703170776 Accuracy: 0.4694531261920929\n",
            "Loss: 1.3568260669708252 Accuracy: 0.49631431698799133\n",
            "Loss: 1.3307772874832153 Accuracy: 0.51953125\n",
            "Loss: 1.4292387962341309 Accuracy: 0.5212500095367432\n",
            "Loss: 1.3421077728271484 Accuracy: 0.5385156273841858\n",
            "Loss: 1.2518442869186401 Accuracy: 0.5476003885269165\n",
            "Loss: 1.234795093536377 Accuracy: 0.5531250238418579\n",
            "Loss: 1.2457221746444702 Accuracy: 0.5617969036102295\n",
            "Loss: 1.2800772190093994 Accuracy: 0.5646874904632568\n",
            "Loss: 1.110159158706665 Accuracy: 0.5752038955688477\n",
            "Loss: 1.1757841110229492 Accuracy: 0.586718738079071\n",
            "Loss: 1.342313289642334 Accuracy: 0.5880468487739563\n",
            "Loss: 1.3094704151153564 Accuracy: 0.5899999737739563\n",
            "Loss: 1.1047327518463135 Accuracy: 0.5995922088623047\n",
            "Loss: 1.193807601928711 Accuracy: 0.5971875190734863\n",
            "Loss: 1.2508161067962646 Accuracy: 0.6028906106948853\n",
            "Loss: 1.2662498950958252 Accuracy: 0.6042187213897705\n",
            "Loss: 1.0548348426818848 Accuracy: 0.6223337650299072\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV3kAt5VYtsQ",
        "outputId": "f444696e-8b18-4dba-86e7-7e9f5b57e503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.5916000008583069\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94Exoh4agMO"
      },
      "source": [
        "An increased size of filter decreased the model performance drastically. A suitable filter size is 3x3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcNc0xrfa3Ni"
      },
      "source": [
        "## Added Strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tRi0RVXafMK",
        "outputId": "69b8790c-a329-4c53-9159-f0c10707bf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1143242 (4.36 MB)\n",
            "Trainable params: 1143242 (4.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbdfJsWMbbqX",
        "outputId": "e91072de-a86f-4267-e78b-60f020fe1d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.3138625621795654 Accuracy: 0.09375\n",
            "Loss: 1.59475839138031 Accuracy: 0.31421875953674316\n",
            "Loss: 1.4651634693145752 Accuracy: 0.48265624046325684\n",
            "Loss: 1.1846867799758911 Accuracy: 0.5353124737739563\n",
            "Loss: 1.1254279613494873 Accuracy: 0.5810068845748901\n",
            "Loss: 1.1055731773376465 Accuracy: 0.6310937404632568\n",
            "Loss: 1.0713804960250854 Accuracy: 0.6449218988418579\n",
            "Loss: 0.8871496915817261 Accuracy: 0.6717968583106995\n",
            "Loss: 0.7683706283569336 Accuracy: 0.6821675300598145\n",
            "Loss: 0.7978931069374084 Accuracy: 0.7138281464576721\n",
            "Loss: 0.7752179503440857 Accuracy: 0.7250781059265137\n",
            "Loss: 0.8164147138595581 Accuracy: 0.7196093797683716\n",
            "Loss: 0.7324307560920715 Accuracy: 0.7398839592933655\n",
            "Loss: 0.8155431747436523 Accuracy: 0.762890636920929\n",
            "Loss: 0.6915146112442017 Accuracy: 0.7577343583106995\n",
            "Loss: 0.5460407733917236 Accuracy: 0.7646874785423279\n",
            "Loss: 0.5950846076011658 Accuracy: 0.7774466872215271\n",
            "Loss: 0.4533497095108032 Accuracy: 0.791796863079071\n",
            "Loss: 0.5426782965660095 Accuracy: 0.7971093654632568\n",
            "Loss: 0.5974148511886597 Accuracy: 0.7918750047683716\n",
            "Loss: 0.6252075433731079 Accuracy: 0.8144604563713074\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJBBdP-8bkU7",
        "outputId": "c2774c71-16e3-4724-c16f-bd2de26c315c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7267000079154968\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_34E0bhsb69G"
      },
      "source": [
        "## Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-91EQ9psbnaN",
        "outputId": "b9685153-004e-466b-a807-a084b5b4d197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               4194816   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4293194 (16.38 MB)\n",
            "Trainable params: 4293194 (16.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmRgZNwRcCPH",
        "outputId": "c200bb56-54eb-4732-a046-dabe8b529389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2944798469543457 Accuracy: 0.0703125\n",
            "Loss: 1.5933644771575928 Accuracy: 0.3631249964237213\n",
            "Loss: 1.408695101737976 Accuracy: 0.5036718845367432\n",
            "Loss: 1.0107203722000122 Accuracy: 0.5653906464576721\n",
            "Loss: 0.8589238524436951 Accuracy: 0.6300972104072571\n",
            "Loss: 0.8569069504737854 Accuracy: 0.662890613079071\n",
            "Loss: 0.9179462194442749 Accuracy: 0.690234363079071\n",
            "Loss: 0.8597216606140137 Accuracy: 0.6974999904632568\n",
            "Loss: 0.7293848991394043 Accuracy: 0.7252979874610901\n",
            "Loss: 0.7211766242980957 Accuracy: 0.7602343559265137\n",
            "Loss: 0.710953414440155 Accuracy: 0.7637500166893005\n",
            "Loss: 0.8530497550964355 Accuracy: 0.7657031416893005\n",
            "Loss: 0.5289110541343689 Accuracy: 0.7823870778083801\n",
            "Loss: 0.5081179141998291 Accuracy: 0.8171093463897705\n",
            "Loss: 0.4137893319129944 Accuracy: 0.8185937404632568\n",
            "Loss: 0.48029178380966187 Accuracy: 0.8204687237739563\n",
            "Loss: 0.27291467785835266 Accuracy: 0.840417206287384\n",
            "Loss: 0.3786478638648987 Accuracy: 0.8726562261581421\n",
            "Loss: 0.4418076276779175 Accuracy: 0.8704687356948853\n",
            "Loss: 0.21520978212356567 Accuracy: 0.8662499785423279\n",
            "Loss: 0.16262365877628326 Accuracy: 0.8948400020599365\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExeVrR-cEaE",
        "outputId": "355bb273-1261-4520-9ddc-5d8ee2a9a8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7577000260353088\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRUTRwmgcdyf"
      },
      "source": [
        "## Removed Pooling and Added Strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWdYdCiAcGoW",
        "outputId": "b1863a40-7981-4aa9-d64e-259e1497702d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_1 (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16876106 (64.38 MB)\n",
            "Trainable params: 16876106 (64.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1,1), padding = \"same\", activation=tf.nn.relu, name = \"conv_1\", input_shape = (32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(filters = 64, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_2\"),\n",
        "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_1\"),\n",
        "    tf.keras.layers.Conv2D(filters = 128, kernel_size=(3, 3), padding = \"same\", activation=tf.nn.relu, name = \"conv_3\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"maxpool_2\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PznThVGSclzj",
        "outputId": "aa9c87a9-bc49-4027-a2c9-32ea392c9b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.307494640350342 Accuracy: 0.109375\n",
            "Loss: 1.5342551469802856 Accuracy: 0.3225781321525574\n",
            "Loss: 1.493888258934021 Accuracy: 0.48656249046325684\n",
            "Loss: 1.1235499382019043 Accuracy: 0.5497656464576721\n",
            "Loss: 1.137096881866455 Accuracy: 0.600768506526947\n",
            "Loss: 1.0631974935531616 Accuracy: 0.6458593606948853\n",
            "Loss: 1.0236141681671143 Accuracy: 0.664843738079071\n",
            "Loss: 0.9227858781814575 Accuracy: 0.6794531345367432\n",
            "Loss: 0.6578063368797302 Accuracy: 0.6950282454490662\n",
            "Loss: 0.8093193173408508 Accuracy: 0.7425000071525574\n",
            "Loss: 0.611315131187439 Accuracy: 0.756640613079071\n",
            "Loss: 0.8680576086044312 Accuracy: 0.7477343678474426\n",
            "Loss: 0.7193264365196228 Accuracy: 0.7698400020599365\n",
            "Loss: 0.419905424118042 Accuracy: 0.8267187476158142\n",
            "Loss: 0.5584357380867004 Accuracy: 0.8220312595367432\n",
            "Loss: 0.5885868668556213 Accuracy: 0.8194531202316284\n",
            "Loss: 0.21550250053405762 Accuracy: 0.8525721430778503\n",
            "Loss: 0.2282962054014206 Accuracy: 0.9095312356948853\n",
            "Loss: 0.4027976393699646 Accuracy: 0.8951562643051147\n",
            "Loss: 0.3272061347961426 Accuracy: 0.8896874785423279\n",
            "Loss: 0.12384213507175446 Accuracy: 0.9183657169342041\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    train_acc_metric(label_batch, logits)\n",
        "\n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afyp2kdAcoA8",
        "outputId": "649ae3cb-3f26-4180-e9e6-b2beb4a584c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.7077000141143799\n"
          ]
        }
      ],
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGcZH4dCcsGC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YKiyaq3PLxR_",
        "9lR4Q_pDNDBP",
        "_9OLiMLFWwO0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
